{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import pickle \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lightning as L\n",
    "seed = 42\n",
    "L.seed_everything(seed, workers=True)\n",
    "\n",
    "from src.models.unet_module import UnetLitModule\n",
    "from src.models.gan_module import UnetGANLitModule\n",
    "from src.models.ae_module import AutoencoderKL, EncoderLRES\n",
    "from src.models.ldm_module import LatentDiffusion\n",
    "\n",
    "from src.models.components.unet import DownscalingUnet\n",
    "from src.models.components.ae import SimpleConvDecoder, SimpleConvEncoder\n",
    "from src.models.components.ldm.denoiser import UNetModel, DDIMSampler\n",
    "from src.models.components.ldm.conditioner import AFNOConditionerNetCascade\n",
    "from src.data.downscaling_datamodule import DownscalingDataModule\n",
    "from src.data.components.downscaling_dataset import DownscalingDataset\n",
    "\n",
    "from utils.inference_utils import get_model_output\n",
    "from utils.plotting_utils import get_target_grid, from_torchtensor_to_xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "trained_models_path = '../pretrained_models/'\n",
    "data_path = '../data/'\n",
    "output_path = '../outputs/'\n",
    "\n",
    "static_vars = {'dtm_tif_file': data_path + 'static_var/dtm_2km_domain_trim_EPSG3035.tif',\n",
    "               'lc_tif_file': data_path + 'static_var/land_cover_classes_2km_domain_trim_EPSG3035.tif',\n",
    "               'lat_tif_file': data_path + 'static_var/lat_2km_domain_trim_EPSG3035.tif'}\n",
    "\n",
    "borders_file = data_path + 'plotting_resources/borders_downscaling_domain_3035.geojson'\n",
    "\n",
    "# Read in the data normalization info\n",
    "with open(data_path + 'normalization_data.pkl', 'rb') as f:\n",
    "    norm_values = pickle.load(f)\n",
    "\n",
    "# Fix number of test timestep to perform\n",
    "nr_timesteps = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the target variables (either '2mT' or 'UV')\n",
    "# target_var = '2mT'\n",
    "target_var = 'UV'\n",
    "\n",
    "target_channels = 1 if target_var == '2mT' else 2\n",
    "target_vars = {'high_res': ['2mT']} if target_var == '2mT' else {'high_res': ['U10', 'V10']}\n",
    "target_vars['low_res'] = ['2mT', 'PMSL', 'U10', 'V10', 'dp2mT', 'SST', 'SNDPT', 'TP', 'SSRadIn', 'Q850', 'T850', 'U850', 'V850', 'W850']\n",
    "\n",
    "tv_idxs = {}\n",
    "for tv in target_vars['high_res']:\n",
    "    tv_idxs[tv] = [i for i in range(len(target_vars['low_res'])) if target_vars['low_res'][i] == tv][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the UNET model \n",
    "ckpt_ref_file = trained_models_path + 'UNET_' + target_var + '.ckpt'\n",
    "loss = torch.nn.Identity()\n",
    "in_ch = 18 + 14  # 18 static variables + 14 predictors\n",
    "out_ch = target_channels\n",
    "unet_model = UnetLitModule.load_from_checkpoint(ckpt_ref_file,\n",
    "                                           net=DownscalingUnet(in_ch=in_ch,out_ch=out_ch),\n",
    "                                           loss=loss,\n",
    "                                           strict=False).eval().to(device='cuda:0')\n",
    "nn_lowres = True\n",
    "# Set up test dataloader\n",
    "data_module_unet = DownscalingDataModule(data_dir=data_path, \n",
    "                                    target_vars=target_vars,\n",
    "                                    batch_size=1,\n",
    "                                    num_workers=1)\n",
    "data_module_unet.data_test = DownscalingDataset(data_path,\n",
    "                                              target_vars=target_vars,\n",
    "                                              nn_lowres=nn_lowres,\n",
    "                                              static_vars=static_vars, \n",
    "                                              metadata_file_name='metadata_test_paper_sample.csv')\n",
    "test_dataloader_unet = data_module_unet.test_dataloader()\n",
    "test_iter_unet = iter(test_dataloader_unet)\n",
    "unet_preds_norm = {}\n",
    "# Run the UNET on the test dataset\n",
    "for idx_preds in tqdm(range(0,nr_timesteps)):           \n",
    "    el = next(test_iter_unet)\n",
    "    model_output, ts_ns = get_model_output('unet-like', unet_model, el)\n",
    "    ts_ns = pd.to_datetime(int(ts_ns))\n",
    "    unet_preds_norm[ts_ns] = {}\n",
    "    for index, tv in enumerate(target_vars['high_res']):\n",
    "        # De-apply normalization\n",
    "        unet_preds_norm[ts_ns][tv] = model_output.cpu()[0,index,:,:]* norm_values['CMCC']['std'][tv] + norm_values['CMCC']['mean'][tv]\n",
    "    if target_var == 'UV':\n",
    "        unet_preds_norm[ts_ns]['WS10'] = np.sqrt(unet_preds_norm[ts_ns]['U10'] **2 + unet_preds_norm[ts_ns]['V10']**2)\n",
    "\n",
    "# Plot data\n",
    "plot_var = '2mT' if target_var=='2mT' else 'WS10'\n",
    "fig, ax_unet = plt.subplots(ncols=nr_timesteps,figsize=(4*nr_timesteps,5),sharey=True, sharex=True, constrained_layout=True)\n",
    "fig.suptitle('UNET')\n",
    "for idx_preds,ts_ns in enumerate(unet_preds_norm):\n",
    "    ax_unet[idx_preds].imshow(unet_preds_norm[ts_ns][plot_var])\n",
    "    ax_unet[idx_preds].set_title(ts_ns, fontsize=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GAN model\n",
    "ckpt_ref_file = trained_models_path + 'GAN_' + target_var + '.ckpt'\n",
    "loss = torch.nn.Identity()\n",
    "in_ch = 18 + 14  # 18 static variables + 14 predictors\n",
    "out_ch = target_channels\n",
    "gan_model = UnetGANLitModule.load_from_checkpoint(ckpt_ref_file,\n",
    "                                              net=DownscalingUnet(in_ch=in_ch,out_ch=out_ch),\n",
    "                                              loss=loss,\n",
    "                                              strict=False).eval().to(device='cuda:0')\n",
    "nn_lowres = True\n",
    "# Set up test dataloader\n",
    "data_module_gan = DownscalingDataModule(data_dir=data_path, \n",
    "                                    target_vars=target_vars,\n",
    "                                    batch_size=1,\n",
    "                                    num_workers=1)\n",
    "data_module_gan.data_test = DownscalingDataset(data_path,\n",
    "                                              target_vars=target_vars,\n",
    "                                              nn_lowres=nn_lowres,\n",
    "                                              static_vars=static_vars, \n",
    "                                              metadata_file_name='metadata_test_paper_sample.csv')\n",
    "test_dataloader_gan = data_module_gan.test_dataloader()\n",
    "test_iter_gan = iter(test_dataloader_gan)\n",
    "gan_preds_norm = {}\n",
    "# Run the GAN on the test dataset\n",
    "for idx_preds in tqdm(range(0,nr_timesteps)):           \n",
    "    el = next(test_iter_gan)\n",
    "    model_output, ts_ns = get_model_output('unet-like', gan_model, el)\n",
    "    ts_ns = pd.to_datetime(int(ts_ns))\n",
    "    gan_preds_norm[ts_ns] = {}\n",
    "    for index, tv in enumerate(target_vars['high_res']):\n",
    "        # De-apply normalization\n",
    "        gan_preds_norm[ts_ns][tv] = model_output.cpu()[0,index,:,:]* norm_values['CMCC']['std'][tv] + norm_values['CMCC']['mean'][tv]\n",
    "    if target_var == 'UV':\n",
    "        gan_preds_norm[ts_ns]['WS10'] = np.sqrt(gan_preds_norm[ts_ns]['U10'] **2 + gan_preds_norm[ts_ns]['V10']**2)\n",
    "\n",
    "# Plot data\n",
    "plot_var = '2mT' if target_var=='2mT' else 'WS10'\n",
    "fig, ax_gan = plt.subplots(ncols=nr_timesteps,figsize=(4*nr_timesteps,5),sharey=True, sharex=True, constrained_layout=True)\n",
    "fig.suptitle('GAN')\n",
    "for idx_preds,ts_ns in enumerate(gan_preds_norm):\n",
    "    ax_gan[idx_preds].imshow(gan_preds_norm[ts_ns][plot_var])\n",
    "    ax_gan[idx_preds].set_title(ts_ns, fontsize=10) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the LDM_res model\n",
    "ckpt_ref_file = trained_models_path + 'LDM_residual_' + target_var + '.ckpt'\n",
    "ae_ckpt_ref_file = trained_models_path + 'VAE_residual_' + target_var + '.ckpt'\n",
    "in_dim = target_channels\n",
    "parameterization = 'v'\n",
    "ae_flag = 'residual'\n",
    "unet_regr = unet_model\n",
    "ldm_res_model = LatentDiffusion.load_from_checkpoint(ckpt_ref_file,\n",
    "                                            denoiser=UNetModel(in_channels=32*in_dim,\n",
    "                                                            model_channels=256,\n",
    "                                                            out_channels=32*in_dim,\n",
    "                                                            num_res_blocks=2,\n",
    "                                                            attention_resolutions=[1,2],\n",
    "                                                            dims=2,\n",
    "                                                            channel_mult=[1,2,4],\n",
    "                                                            num_heads=8,\n",
    "                                                            context_ch=[256,512,1024]),\n",
    "                                            autoencoder=AutoencoderKL(encoder=SimpleConvEncoder(in_dim=in_dim, levels=3),\n",
    "                                                                      decoder=SimpleConvDecoder(in_dim=in_dim, levels=3),\n",
    "                                                                      ae_flag=ae_flag, \n",
    "                                                                      unet_regr=unet_regr),\n",
    "                                            context_encoder=AFNOConditionerNetCascade(autoencoder=[AutoencoderKL(encoder=SimpleConvEncoder(in_dim=18,levels=3,ch_mult=3),\n",
    "                                                                                                             decoder=None),\n",
    "                                                                                               EncoderLRES()], \n",
    "                                                                                  train_autoenc=False,\n",
    "                                                                                  cascade_depth=3,\n",
    "                                                                                  embed_dim=[128,24],\n",
    "                                                                                  analysis_depth=[4,4],\n",
    "                                                                                  afno_fusion=True,\n",
    "                                                                                  input_size_ratios=[1,1],\n",
    "                                                                                  embed_dim_out=256),\n",
    "                                            ae_load_state_file=ae_ckpt_ref_file, \n",
    "                                            parameterization=parameterization).eval().to(device='cuda:0')\n",
    "nn_lowres = False\n",
    "# Set up test dataloader\n",
    "data_module_ldm = DownscalingDataModule(data_dir=data_path, \n",
    "                                    target_vars=target_vars,\n",
    "                                    batch_size=1,\n",
    "                                    num_workers=1)\n",
    "data_module_ldm.data_test = DownscalingDataset(data_path,\n",
    "                                              target_vars=target_vars,\n",
    "                                              nn_lowres=nn_lowres,\n",
    "                                              static_vars=static_vars, \n",
    "                                              metadata_file_name='metadata_test_paper_sample.csv')\n",
    "test_dataloader_ldm = data_module_ldm.test_dataloader()\n",
    "test_iter_ldm = iter(test_dataloader_ldm)\n",
    "# Set up sampler\n",
    "sampler = DDIMSampler(ldm_res_model)\n",
    "denoising_steps = 100\n",
    "\n",
    "ldm_preds_norm = {}\n",
    "# Run the LDM on the test dataset\n",
    "for idx_preds in tqdm(range(0,nr_timesteps)):          \n",
    "    el = next(test_iter_ldm)\n",
    "    model_output, ts_ns = get_model_output('ldm', ldm_res_model, el, sampler=sampler, num_diffusion_iters=denoising_steps)\n",
    "    ts_ns = pd.to_datetime(int(ts_ns))\n",
    "    ldm_preds_norm[ts_ns] = {}\n",
    "    for index, tv in enumerate(target_vars['high_res']):\n",
    "        # De-apply normalization\n",
    "        ldm_preds_norm[ts_ns][tv] = model_output.cpu()[0,index,:,:]* norm_values['CMCC']['std'][tv] + norm_values['CMCC']['mean'][tv]\n",
    "    if target_var == 'UV':\n",
    "        ldm_preds_norm[ts_ns]['WS10'] = np.sqrt(ldm_preds_norm[ts_ns]['U10'] **2 + ldm_preds_norm[ts_ns]['V10']**2)\n",
    "\n",
    "# Plot data\n",
    "plot_var = '2mT' if target_var=='2mT' else 'WS10'\n",
    "fig, ax_ldm = plt.subplots(ncols=nr_timesteps,figsize=(4*nr_timesteps,5),sharey=True, sharex=True, constrained_layout=True)\n",
    "fig.suptitle('LDM_res')\n",
    "for idx_preds,ts_ns in enumerate(ldm_preds_norm):\n",
    "    ax_ldm[idx_preds].imshow(ldm_preds_norm[ts_ns][plot_var])\n",
    "    ax_ldm[idx_preds].set_title(ts_ns, fontsize=10) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store ERA5 and COSMO-CLM baseline datasets\n",
    "test_iter_unet = iter(test_dataloader_unet)\n",
    "era5_norm = {}\n",
    "cosmo_norm = {}\n",
    "\n",
    "for idx_preds in tqdm(range(0,nr_timesteps)):\n",
    "    el = next(test_iter_unet)\n",
    "    low_res = el[0]\n",
    "    high_res = el[1]\n",
    "    ts_ns = pd.to_datetime(int(el[2]))\n",
    "    era5_norm[ts_ns] = {}\n",
    "    cosmo_norm[ts_ns] = {}\n",
    "    for index, tv in enumerate(target_vars['high_res']):\n",
    "        # De-apply normalization\n",
    "        era5_norm[ts_ns][tv] = low_res[0, tv_idxs[tv],:,:]* norm_values['ERA5']['std'][tv] + norm_values['ERA5']['mean'][tv]\n",
    "        cosmo_norm[ts_ns][tv] = high_res[0,index,:,:]* norm_values['CMCC']['std'][tv] + norm_values['CMCC']['mean'][tv]\n",
    "    if target_var == 'UV':\n",
    "        era5_norm[ts_ns]['WS10'] = np.sqrt(era5_norm[ts_ns]['U10'] **2 + era5_norm[ts_ns]['V10']**2)\n",
    "        cosmo_norm[ts_ns]['WS10'] = np.sqrt(cosmo_norm[ts_ns]['U10'] **2 + cosmo_norm[ts_ns]['V10']**2)\n",
    "\n",
    "# Store Quadratic Interp. baseline datasets\n",
    "test_iter_ldm = iter(test_dataloader_ldm)\n",
    "quadratic_norm = {}\n",
    "\n",
    "target_grid_low_res = get_target_grid('low')\n",
    "target_grid_high_res = get_target_grid('high')\n",
    "\n",
    "for idx_preds in tqdm(range(0,nr_timesteps)):\n",
    "    el = next(test_iter_ldm)\n",
    "    low_res = el[0]\n",
    "    ts_ns = pd.to_datetime(int(el[3]))\n",
    "    quadratic_norm[ts_ns] = {}\n",
    "    for index, tv in enumerate(target_vars['high_res']):\n",
    "        # De-apply normalization\n",
    "        era5_xr = from_torchtensor_to_xarray(low_res[0, tv_idxs[tv],:,:], target_grid_low_res, coords_name='y_x')\n",
    "        quadratic_interp = era5_xr.interp_like(target_grid_high_res, method='quadratic', assume_sorted=False, kwargs={\"fill_value\": \"extrapolate\"})\n",
    "        quadratic_interp = torch.from_numpy(quadratic_interp.values)\n",
    "        quadratic_norm[ts_ns][tv] = quadratic_interp* norm_values['ERA5']['std'][tv] + norm_values['ERA5']['mean'][tv]\n",
    "    if target_var == 'UV':\n",
    "        quadratic_norm[ts_ns]['WS10'] = np.sqrt(quadratic_norm[ts_ns]['U10'] **2 + quadratic_norm[ts_ns]['V10']**2)   \n",
    "\n",
    "# Plot data\n",
    "mod_list = {'ERA5': era5_norm, 'COSMO-CLM': cosmo_norm, 'Quadratic Interp.': quadratic_norm}\n",
    "for mod_i in mod_list:\n",
    "    fig, ax = plt.subplots(ncols=nr_timesteps,figsize=(4*nr_timesteps,5),sharey=True, sharex=True, constrained_layout=True)\n",
    "    fig.suptitle(mod_i)\n",
    "    for idx_preds,ts_ns in enumerate(quadratic_norm):\n",
    "        ax[idx_preds].imshow(mod_list[mod_i][ts_ns][plot_var])\n",
    "        ax[idx_preds].set_title(ts_ns, fontsize=10) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for saving results and later plotting\n",
    "results = {'ERA5': era5_norm, \n",
    "           'COSMO-CLM': cosmo_norm,\n",
    "           'Quadratic Interp.': quadratic_norm,\n",
    "           'UNET': unet_preds_norm,\n",
    "           'GAN': gan_preds_norm,\n",
    "           'LDM_res': ldm_preds_norm}\n",
    "\n",
    "d = []\n",
    "for mod_i in results:\n",
    "    for ts in results[mod_i]:\n",
    "        pred_ts = results[mod_i][ts]\n",
    "        # print(pred_ts.dims)\n",
    "        for tv in target_vars['high_res']:\n",
    "            d.append({'input_var': 'all',\n",
    "                      'target_var': target_var,\n",
    "                      'model': mod_i,\n",
    "                      'variable': tv,\n",
    "                      'spat_distr': pred_ts[tv],\n",
    "                      'min': np.percentile(pred_ts[tv],0.5),\n",
    "                      'max': np.percentile(pred_ts[tv],99.5),\n",
    "                      'time_step': ts})\n",
    "        if target_var == 'UV':\n",
    "            d.append({'input_var': 'all',\n",
    "                      'target_var': target_var,\n",
    "                      'model': mod_i,\n",
    "                      'variable': 'WS10',\n",
    "                      'spat_distr': pred_ts['WS10'],\n",
    "                      'min': np.percentile(pred_ts['WS10'],0.5),\n",
    "                      'max': np.percentile(pred_ts['WS10'],99.5),\n",
    "                      'time_step': ts})\n",
    "results_df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results for later plotting\n",
    "results_df.to_pickle(output_path + './results_trained_models_' + target_var + '.pkl')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the VAE model\n",
    "# ckpt_ref_file = trained_models_path + 'VAE_' + target_var + '.ckpt'\n",
    "# in_dim = target_channels\n",
    "# ae_flag = 'residual'\n",
    "# unet_regr = unet_model\n",
    "# vae_model = AutoencoderKL.load_from_checkpoint(ckpt_ref_file,\n",
    "#                                         encoder=SimpleConvEncoder(in_dim=in_dim, levels=3),\n",
    "#                                         decoder=SimpleConvDecoder(in_dim=in_dim, levels=3),\n",
    "#                                         ae_flag=ae_flag,\n",
    "#                                         unet_regr = unet_regr).eval().to(device='cuda:0')      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
